{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch. multiprocessing as mp\n",
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./data\")\n",
    "if data_path.is_dir():\n",
    "  !rm -fd data/*/*/* data/*/* data/* data\n",
    "data_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import model, data \n",
    "effnetb2_v2_m, train_transforms, test_transforms = model.create_effnetb2_v2_m(102)\n",
    "train_dataloader, test_dataloader, val_dataloader = data.create_dataloaders(root=data_path,\n",
    "                                                                            train_transforms=train_transforms,\n",
    "                                                                            test_transforms=test_transforms,\n",
    "                                                                            batch_size=128,\n",
    "                                                                            device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_path = Path(\"./data/flowers-102/jpg/\")\n",
    "random_img_paths = random.sample(list(os.listdir(img_path)), k=5)\n",
    "fig, ax = plt.subplots(nrows=5, ncols=1, figsize=(18,12))\n",
    "for idx, pth in enumerate(random_img_paths):\n",
    "  img = Image.open(img_path/pth)\n",
    "  ax[idx].imshow(img)\n",
    "  ax[idx].axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effnetb2_v2_m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.Adam(effnetb2_v2_m.parameters(), lr=1e-3)\n",
    "EPOCHS=30\n",
    "compile_model = torch.compile(effnetb2_v2_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import train\n",
    "results = train.train_model(model=compile_model,\n",
    "                      train_dataloader=train_dataloader,\n",
    "                      test_dataloader=test_dataloader,\n",
    "                      optimizer=optimizer,\n",
    "                      loss_fn=loss_fn,\n",
    "                      device=device,\n",
    "                      epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "results_df = pd.DataFrame(results) \n",
    "results_df.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=effnetb2_v2_m.state_dict(),f=\"./flower102_effnetb2_v2_m.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://gist.githubusercontent.com/JosephKJ/94c7728ed1a8e0cd87fe6a029769cde1/raw/403325f5110cb0f3099734c5edb9f457539c77e9/Oxford-102_Flower_dataset_labels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Oxford-102_Flower_dataset_labels.txt\", \"r\") as f:\n",
    "  class_names= [name for name in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_img = random.randint(0, 127)\n",
    "effnetb2_v2_m.eval()\n",
    "with torch.inference_mode():\n",
    "  img = val[0][random_img]\n",
    "  img_converted = img.unsqueeze(dim=0)\n",
    "  img_converted = effnetb2_v2_m(img_converted.to(device))\n",
    "  pred_label = torch.argmax(torch.softmax(img_converted, dim=1), dim=1)\n",
    "  plt.imshow(img.cpu().permute(1, 2, 0));\n",
    "  plt.title(f\"Prediction Label: {class_names[pred_label.max()]} | Label: {class_names[val[1][random_img]]}\")\n",
    "  plt.axis(\"off\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
